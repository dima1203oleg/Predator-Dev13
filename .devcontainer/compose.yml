version: "3.9"
services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: predator
      POSTGRES_PASSWORD: predator
      POSTGRES_DB: predator
    ports: ["5432:5432"]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U predator -d predator"]
      interval: 5s
      timeout: 3s
      retries: 20
    volumes: ["pgdata:/var/lib/postgresql/data"]
    profiles: ["core"]

  opensearch:
    image: opensearchproject/opensearch:2.14.0
    environment:
      discovery.type: single-node
      plugins.security.disabled: "true"
      OPENSEARCH_JAVA_OPTS: "-Xms512m -Xmx512m"
    ports: ["9200:9200", "9600:9600"]
    ulimits: { memlock: { soft: -1, hard: -1 } }
    profiles: ["core"]

  qdrant:
    image: qdrant/qdrant:v1.11.0
    ports: ["6333:6333"]
    volumes: ["qdrantdata:/qdrant/storage"]
    profiles: ["core"]

  minio:
    image: minio/minio:RELEASE.2025-01-10T00-00-00Z
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio12345
    ports: ["9000:9000", "9001:9001"]
    volumes: ["miniodata:/data"]
    profiles: ["core"]

  redis:
    image: redis:7
    ports: ["6379:6379"]
    profiles: ["core"]

  rabbitmq:
    image: rabbitmq:3-management
    ports: ["5672:5672", "15672:15672"]
    profiles: ["core"]

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    command: mlflow server --host 0.0.0.0 --port 5002 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlruns
    ports: ["5002:5002"]
    volumes: ["mlruns:/mlruns"]
    profiles: ["ml"]

  neo4j:
    image: neo4j:5
    environment:
      NEO4J_AUTH: neo4j/password
    ports: ["7474:7474", "7687:7687"]
    profiles: ["graph"]

  keycloak:
    image: quay.io/keycloak/keycloak:25.0
    command: start-dev
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    ports: ["8080:8080"]
    profiles: ["security"]

  ollama:
    image: ollama/ollama:latest
    environment:
      OLLAMA_KEEP_ALIVE: "24h"
    volumes: ["ollama:/root/.ollama"]
    ports: ["11434:11434"]
    profiles: ["ml"]

  whisper:
    image: ghcr.io/ggerganov/whisper.cpp:server
    command:
      ["-l", "uk", "-ngl", "1", "-m", "/models/ggml-base.bin", "-pp", "8081"]
    ports: ["8081:8081"]
    profiles: ["voice"]

  kafka:
    image: docker.redpanda.com/vectorized/redpanda:v24.2.3
    command:
      [
        "redpanda",
        "start",
        "--overprovisioned",
        "--smp",
        "1",
        "--memory",
        "512M",
        "--reserve-memory",
        "0M",
      ]
    ports: ["9092:9092"]
    profiles: ["events"]

  grafana:
    image: grafana/grafana:11
    ports: ["3000:3000"]
    profiles: ["obs"]

  prometheus:
    image: prom/prometheus:v2.54.1
    ports: ["9090:9090"]
    profiles: ["obs"]

  loki:
    image: grafana/loki:2.9.8
    ports: ["3100:3100"]
    profiles: ["obs"]

  tempo:
    image: grafana/tempo:2.6.0
    ports: ["3200:3200"]
    profiles: ["obs"]

volumes:
  pgdata: {}
  qdrantdata: {}
  miniodata: {}
  mlruns: {}
  ollama: {}
